#!/usr/bin/env python3
"""
ä½¿ç”¨PnP-Flowæ–¹æ³•æµ‹è¯•CropSRè¶…åˆ†è¾¨ç‡ä»»åŠ¡
åŸºäºé¢„è®­ç»ƒçš„Flow Matchingæ¨¡å‹è¿›è¡Œæ¡ä»¶å›¾åƒæ¢å¤
"""

import torch
import numpy as np
import sys
import os
import argparse
from PIL import Image
import torch.nn.functional as F
from time import perf_counter

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')
from pnpflow.utils import define_model, load_cfg_from_cfg_file, postprocess
from pnpflow.train_flow_matching import FLOW_MATCHING
from pnpflow.dataloaders import DataLoaders
from pnpflow.degradations import Superresolution
from pnpflow.methods.pnp_flow import PNP_FLOW
import pnpflow.utils as utils

class SimpleSuperresolution:
    """ç®€åŒ–çš„è¶…åˆ†è¾¨ç‡é™è´¨ç±»ï¼Œé¿å…åˆ›å»ºå·¨å¤§çš„é™é‡‡æ ·çŸ©é˜µ"""
    def __init__(self, sf, dim_image, device="cuda"):
        self.sf = sf
        self.device = device
        
    def H(self, x):
        """é™é‡‡æ ·æ“ä½œï¼šHR -> LR"""
        return utils.downsample(x, self.sf)
    
    def H_adj(self, x):
        """ä¸Šé‡‡æ ·æ“ä½œï¼šLR -> HR (åŒä¸‰æ¬¡æ’å€¼)"""
        return utils.upsample(x, self.sf)

class Args:
    """é…ç½®ç±»ï¼Œæ¨¡æ‹Ÿargparseå‚æ•°"""
    def __init__(self, cfg, num_samples=8):
        # ä»é…ç½®æ–‡ä»¶å¤åˆ¶åŸºæœ¬å‚æ•°
        for key, value in cfg.items():
            setattr(self, key, value)
        
        # PnP-Flowç‰¹å®šå‚æ•°
        self.method = 'pnp_flow'
        self.problem = 'superresolution'
        self.noise_type = 'gaussian'
        self.sigma_noise = 0.05
        self.max_batch = num_samples  # ä½¿ç”¨ä¼ å…¥çš„æ ·æœ¬æ•°é‡
        self.batch_size_ip = 1  # æ¯æ¬¡å¤„ç†ä¸€å¼ å›¾åƒ
        self.eval_split = 'test'
        
        # PnP-Flowç®—æ³•å‚æ•° 4x
        self.steps_pnp = 200  # PnPè¿­ä»£æ­¥æ•°
        self.lr_pnp = 1.5     # å­¦ä¹ ç‡
        self.num_samples = 3   # æ¯æ­¥é‡‡æ ·æ•°é‡ï¼ˆå¢åŠ é‡‡æ ·æé«˜ç¨³å®šæ€§ï¼‰
        self.gamma_style = 'constant'  # å­¦ä¹ ç‡ç­–ç•¥
        self.alpha = 1.0

        # PnP-Flowç®—æ³•å‚æ•° 8x
        # self.steps_pnp = 150  # PnPè¿­ä»£æ­¥æ•°
        # self.lr_pnp = 2.0     # å­¦ä¹ ç‡
        # self.num_samples = 8   # æ¯æ­¥é‡‡æ ·æ•°é‡ï¼ˆå¢åŠ é‡‡æ ·æé«˜ç¨³å®šæ€§ï¼‰
        # self.gamma_style = 'constant'  # å­¦ä¹ ç‡ç­–ç•¥
        # self.alpha = 1.0
        
        # ä¿å­˜å’Œè®¡ç®—é€‰é¡¹
        self.save_results = True
        self.compute_time = False
        self.compute_memory = False
        
        # åˆ›å»ºå­—å…¸ç”¨äºä¿å­˜è·¯å¾„
        self.dict_cfg_method = {
            'steps_pnp': self.steps_pnp,
            'lr_pnp': self.lr_pnp,
            'num_samples': self.num_samples,
            'gamma_style': self.gamma_style
        }

def load_8x_data(lr_path, hr_path, num_samples, device, start_idx=0):
    """ä»æŒ‡å®šè·¯å¾„åŠ è½½8å€è¶…åˆ†è¾¨ç‡æ•°æ®"""
    print(f"=== åŠ è½½8å€è¶…åˆ†è¾¨ç‡æ•°æ® ===")
    print(f"LRè·¯å¾„: {lr_path}")
    print(f"HRè·¯å¾„: {hr_path}")
    print(f"èµ·å§‹ç´¢å¼•: {start_idx}")
    
    # è·å–æ–‡ä»¶åˆ—è¡¨
    lr_files = sorted([f for f in os.listdir(lr_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    hr_files = sorted([f for f in os.listdir(hr_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    
    print(f"æ‰¾åˆ° {len(lr_files)} ä¸ªLRæ–‡ä»¶, {len(hr_files)} ä¸ªHRæ–‡ä»¶")
    
    # ç¡®ä¿èµ·å§‹ç´¢å¼•æœ‰æ•ˆ
    max_start_idx = min(len(lr_files), len(hr_files)) - num_samples
    if start_idx > max_start_idx:
        start_idx = max_start_idx
        print(f"è°ƒæ•´èµ·å§‹ç´¢å¼•ä¸º: {start_idx}")
    
    # é€‰æ‹©æŒ‡å®šèŒƒå›´çš„æ–‡ä»¶
    end_idx = start_idx + num_samples
    selected_lr_files = lr_files[start_idx:end_idx]
    selected_hr_files = hr_files[start_idx:end_idx]
    
    print(f"é€‰æ‹©æ–‡ä»¶èŒƒå›´: {start_idx} åˆ° {end_idx-1}")
    print(f"ç¬¬ä¸€ä¸ªæ–‡ä»¶: {selected_lr_files[0]} / {selected_hr_files[0]}")
    print(f"æœ€åä¸€ä¸ªæ–‡ä»¶: {selected_lr_files[-1]} / {selected_hr_files[-1]}")
    
    lr_images = []
    hr_images = []
    
    for i, (lr_file, hr_file) in enumerate(zip(selected_lr_files, selected_hr_files)):
        # åŠ è½½LRå›¾åƒ
        lr_img = Image.open(os.path.join(lr_path, lr_file)).convert('RGB')
        lr_tensor = torch.from_numpy(np.array(lr_img)).float().permute(2, 0, 1) / 255.0
        lr_images.append(lr_tensor)
        
        # åŠ è½½HRå›¾åƒ
        hr_img = Image.open(os.path.join(hr_path, hr_file)).convert('RGB')
        hr_tensor = torch.from_numpy(np.array(hr_img)).float().permute(2, 0, 1) / 255.0
        hr_images.append(hr_tensor)
        
        if i == 0:
            print(f"LRå›¾åƒå°ºå¯¸: {lr_tensor.shape}")
            print(f"HRå›¾åƒå°ºå¯¸: {hr_tensor.shape}")
    
    lr_images = torch.stack(lr_images)
    hr_images = torch.stack(hr_images)
    
    print(f"åŠ è½½å®Œæˆ: LR {lr_images.shape}, HR {hr_images.shape}")
    return lr_images, hr_images

def clear_gpu_memory():
    """æ¸…ç†GPUæ˜¾å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("GPUæ˜¾å­˜å·²æ¸…ç†")

def load_model_and_config(model_path, device):
    """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
    print("=== åŠ è½½é…ç½®å’Œæ¨¡å‹ ===")
    
    # åŠ è½½é…ç½®
    cfg = load_cfg_from_cfg_file('./config/main_config.yaml')
    dataset_config = cfg.root + f'config/dataset_config/{cfg.dataset}.yaml'
    cfg.update(load_cfg_from_cfg_file(dataset_config))
    
    print(f"æ•°æ®é›†: {cfg.dataset}")
    print(f"å›¾åƒå°ºå¯¸: {cfg.dim_image}x{cfg.dim_image}")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model, state = define_model(cfg)
    model = model.to(device)
    
    # åŠ è½½æƒé‡
    if os.path.exists(model_path):
        print(f"åŠ è½½æ¨¡å‹: {model_path}")
        model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))
        model.eval()
        print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())/1e6:.2f}M")
    else:
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    return model, cfg

def create_lr_images(hr_images, degradation, sigma_noise, device, seed=42):
    """åˆ›å»ºLRå›¾åƒï¼ˆæ¨¡æ‹ŸçœŸå®çš„è¶…åˆ†è¾¨ç‡ä»»åŠ¡ï¼‰"""
    print("=== åˆ›å»ºLRå›¾åƒ ===")
    
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
    torch.manual_seed(seed)
    
    lr_images = []
    for i, hr_img in enumerate(hr_images):
        hr_single = hr_img.unsqueeze(0).to(device)
        
        # åº”ç”¨é™è´¨æ“ä½œ
        lr_single = degradation.H(hr_single)
        
        # æ·»åŠ å™ªå£°
        if sigma_noise > 0:
            lr_single += torch.randn_like(lr_single) * sigma_noise
        
        lr_images.append(lr_single.cpu())
        
        print(f"åˆ›å»ºç¬¬ {i+1} å¼ LRå›¾åƒ")
        print(f"  HRå½¢çŠ¶: {hr_single.shape}, å€¼åŸŸ: [{hr_single.min():.3f}, {hr_single.max():.3f}]")
        print(f"  LRå½¢çŠ¶: {lr_single.shape}, å€¼åŸŸ: [{lr_single.min():.3f}, {lr_single.max():.3f}]")
    
    return torch.cat(lr_images, dim=0)

def save_comparison_images(hr_images, lr_images, restored_images, bicubic_images, cfg, save_dir="./test_results"):
    """ä¿å­˜å››ç§å›¾åƒçš„å¯¹æ¯”ï¼šHRçœŸå®ã€LRè¾“å…¥ã€åŒä¸‰æ¬¡æ’å€¼ã€PnP-Flowæ¢å¤"""
    print(f"=== ä¿å­˜å¯¹æ¯”å›¾åƒåˆ° {save_dir} ===")
    os.makedirs(save_dir, exist_ok=True)
    
    # åå¤„ç†å›¾åƒç”¨äºä¿å­˜
    hr_processed = postprocess(hr_images, cfg)
    lr_processed = postprocess(lr_images, cfg)
    restored_processed = postprocess(restored_images, cfg)
    bicubic_processed = postprocess(bicubic_images, cfg)
    
    # ç¡®ä¿å€¼åŸŸåœ¨[0,1]å¹¶è½¬æ¢ä¸ºuint8
    hr_processed = torch.clamp(hr_processed, 0, 1)
    lr_processed = torch.clamp(lr_processed, 0, 1)
    restored_processed = torch.clamp(restored_processed, 0, 1)
    bicubic_processed = torch.clamp(bicubic_processed, 0, 1)
    
    for i in range(len(hr_images)):
        # HRçœŸå®å›¾åƒ
        hr_img = (hr_processed[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        Image.fromarray(hr_img).save(f"{save_dir}/HR_GT_{i:02d}.png")
        
        # LRè¾“å…¥å›¾åƒ
        lr_img = (lr_processed[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        Image.fromarray(lr_img).save(f"{save_dir}/LR_Input_{i:02d}.png")
        
        # åŒä¸‰æ¬¡æ’å€¼ç»“æœ
        bicubic_img = (bicubic_processed[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        Image.fromarray(bicubic_img).save(f"{save_dir}/Bicubic_Upsampled_{i:02d}.png")
        
        # PnP-Flowæ¢å¤ç»“æœ
        restored_img = (restored_processed[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        Image.fromarray(restored_img).save(f"{save_dir}/Restored_PnPFlow_{i:02d}.png")
        
        print(f"å·²ä¿å­˜ç¬¬ {i+1} ç»„å¯¹æ¯”å›¾åƒ")
    
    print("æ–‡ä»¶å‘½åè§„åˆ™:")
    print("  HR_GT_XX.png: é«˜åˆ†è¾¨ç‡çœŸå®å›¾åƒ (Ground Truth)")
    print("  LR_Input_XX.png: ä½åˆ†è¾¨ç‡è¾“å…¥å›¾åƒ")
    print("  Bicubic_Upsampled_XX.png: åŒä¸‰æ¬¡æ’å€¼ä¸Šé‡‡æ ·ç»“æœ")
    print("  Restored_PnPFlow_XX.png: PnP-Flowæ¢å¤çš„å›¾åƒ")

def calculate_metrics(hr_images, restored_images, cfg):
    """è®¡ç®—PSNRå’ŒSSIMæŒ‡æ ‡"""
    print("=== è®¡ç®—è¯„ä¼°æŒ‡æ ‡ ===")
    
    # åå¤„ç†åˆ°[0,1]èŒƒå›´ç”¨äºæŒ‡æ ‡è®¡ç®—
    hr_processed = postprocess(hr_images, cfg)
    restored_processed = postprocess(restored_images, cfg)
    
    # ç¡®ä¿å€¼åŸŸåœ¨[0,1]
    hr_processed = torch.clamp(hr_processed, 0, 1)
    restored_processed = torch.clamp(restored_processed, 0, 1)
    
    # è®¡ç®—PSNR
    mse = torch.mean((hr_processed - restored_processed) ** 2)
    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
    print(f"PSNR: {psnr.item():.4f} dB")
    
    # è®¡ç®—SSIM
    def ssim_single_channel(img1, img2):
        mu1 = F.avg_pool2d(img1, 3, 1, 1)
        mu2 = F.avg_pool2d(img2, 3, 1, 1)
        mu1_sq = mu1.pow(2)
        mu2_sq = mu2.pow(2)
        mu1_mu2 = mu1 * mu2
        
        sigma1_sq = F.avg_pool2d(img1 * img1, 3, 1, 1) - mu1_sq
        sigma2_sq = F.avg_pool2d(img2 * img2, 3, 1, 1) - mu2_sq
        sigma12 = F.avg_pool2d(img1 * img2, 3, 1, 1) - mu1_mu2
        
        C1 = 0.01 ** 2
        C2 = 0.03 ** 2
        
        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
        return ssim_map.mean()
    
    # å¯¹æ¯ä¸ªé€šé“è®¡ç®—SSIM
    ssim_values = []
    for c in range(hr_processed.shape[1]):
        ssim_c = ssim_single_channel(hr_processed[:, c:c+1], restored_processed[:, c:c+1])
        ssim_values.append(ssim_c)
    
    ssim = torch.mean(torch.stack(ssim_values))
    print(f"SSIM: {ssim.item():.4f}")
    
    return psnr.item(), ssim.item()

def calculate_baseline_metrics(hr_images, lr_images, cfg):
    """è®¡ç®—LRåŒä¸‰æ¬¡æ’å€¼ä¸Šé‡‡æ ·çš„åŸºçº¿æŒ‡æ ‡"""
    print("=== è®¡ç®—åŒä¸‰æ¬¡æ’å€¼åŸºçº¿æŒ‡æ ‡ ===")
    
    # å¯¹LRå›¾åƒè¿›è¡ŒåŒä¸‰æ¬¡æ’å€¼ä¸Šé‡‡æ ·
    sf = hr_images.shape[-1] // lr_images.shape[-1]  # è®¡ç®—æ”¾å¤§å€æ•°
    bicubic_upsampled = F.interpolate(lr_images, scale_factor=sf, mode='bicubic', align_corners=False)
    
    # åå¤„ç†åˆ°[0,1]èŒƒå›´
    hr_processed = postprocess(hr_images, cfg)
    bicubic_processed = postprocess(bicubic_upsampled, cfg)
    
    # ç¡®ä¿å€¼åŸŸåœ¨[0,1]
    hr_processed = torch.clamp(hr_processed, 0, 1)
    bicubic_processed = torch.clamp(bicubic_processed, 0, 1)
    
    # è®¡ç®—PSNR
    mse = torch.mean((hr_processed - bicubic_processed) ** 2)
    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
    print(f"åŒä¸‰æ¬¡æ’å€¼ PSNR: {psnr.item():.4f} dB")
    
    # è®¡ç®—SSIM
    def ssim_single_channel(img1, img2):
        mu1 = F.avg_pool2d(img1, 3, 1, 1)
        mu2 = F.avg_pool2d(img2, 3, 1, 1)
        mu1_sq = mu1.pow(2)
        mu2_sq = mu2.pow(2)
        mu1_mu2 = mu1 * mu2
        
        sigma1_sq = F.avg_pool2d(img1 * img1, 3, 1, 1) - mu1_sq
        sigma2_sq = F.avg_pool2d(img2 * img2, 3, 1, 1) - mu2_sq
        sigma12 = F.avg_pool2d(img1 * img2, 3, 1, 1) - mu1_mu2
        
        C1 = 0.01 ** 2
        C2 = 0.03 ** 2
        
        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
        return ssim_map.mean()
    
    # å¯¹æ¯ä¸ªé€šé“è®¡ç®—SSIM
    ssim_values = []
    for c in range(hr_processed.shape[1]):
        ssim_c = ssim_single_channel(hr_processed[:, c:c+1], bicubic_processed[:, c:c+1])
        ssim_values.append(ssim_c)
    
    ssim = torch.mean(torch.stack(ssim_values))
    print(f"åŒä¸‰æ¬¡æ’å€¼ SSIM: {ssim.item():.4f}")
    
    return psnr.item(), ssim.item(), bicubic_upsampled

def run_pnp_flow_test(model, cfg, device, num_samples=8, save_dir="./test_results", 
                      scale_factor=2, lr_data_path=None, hr_data_path=None, start_idx=0):
    """è¿è¡ŒPnP-Flowè¶…åˆ†è¾¨ç‡æµ‹è¯•"""
    print("=== å¼€å§‹PnP-Flowè¶…åˆ†è¾¨ç‡æµ‹è¯• ===")
    
    # åˆ›å»ºå‚æ•°å¯¹è±¡
    args = Args(cfg, num_samples)
    args.save_path = save_dir
    
    # è®¾ç½®è¶…åˆ†è¾¨ç‡å€æ•°
    sf = scale_factor
    print(f'è¶…åˆ†è¾¨ç‡å€æ•°: {sf}x')
    
    # æ ¹æ®æ˜¯å¦æä¾›å¤–éƒ¨æ•°æ®è·¯å¾„é€‰æ‹©æ•°æ®åŠ è½½æ–¹å¼
    if scale_factor == 8 and lr_data_path and hr_data_path:
        # 8å€è¶…åˆ†è¾¨ç‡ï¼šä»æŒ‡å®šè·¯å¾„åŠ è½½æ•°æ®
        lr_images, hr_images = load_8x_data(lr_data_path, hr_data_path, num_samples, device, start_idx)
        print(f"ä»å¤–éƒ¨è·¯å¾„åŠ è½½äº† {len(hr_images)} å¼ å›¾åƒ")
        print(f"LRå½¢çŠ¶: {lr_images.shape}, HRå½¢çŠ¶: {hr_images.shape}")
        
        # éªŒè¯å°ºå¯¸å…³ç³»
        actual_sf = hr_images.shape[-1] // lr_images.shape[-1]
        print(f"å®é™…è¶…åˆ†è¾¨ç‡å€æ•°: {actual_sf}x")
        if actual_sf != sf:
            print(f"è­¦å‘Š: æœŸæœ›å€æ•° {sf}xï¼Œä½†å®é™…å€æ•°ä¸º {actual_sf}x")
            sf = actual_sf  # ä½¿ç”¨å®é™…å€æ•°
        
        # ä½¿ç”¨HRå›¾åƒçš„å°ºå¯¸ä½œä¸ºç›®æ ‡å°ºå¯¸
        target_dim = hr_images.shape[-1]
        degradation = SimpleSuperresolution(sf, target_dim, device)
        sigma_noise = args.sigma_noise
        
        print(f"ä½¿ç”¨å¤–éƒ¨æ•°æ®ï¼Œç›®æ ‡å°ºå¯¸: {target_dim}")
    else:
        # 2x/4xè¶…åˆ†è¾¨ç‡ï¼šä»æ•°æ®é›†åŠ è½½å¹¶ç”ŸæˆLRå›¾åƒ
        print("ä»æ•°æ®é›†åŠ è½½æµ‹è¯•æ•°æ®...")
        
        # ä½¿ç”¨bicubicæ¨¡å¼é¿å…å·¨å¤§çš„é™é‡‡æ ·çŸ©é˜µ
        print("ä½¿ç”¨åŒä¸‰æ¬¡æ’å€¼æ¨¡å¼è¿›è¡Œè¶…åˆ†è¾¨ç‡ï¼ˆé¿å…æ˜¾å­˜é—®é¢˜ï¼‰")
        degradation = SimpleSuperresolution(sf, cfg.dim_image, device)
        sigma_noise = args.sigma_noise
        
        data_loaders = DataLoaders(cfg.dataset, num_samples, num_samples).load_data()
        test_loader = data_loaders['test']
        
        # è·å–HRå›¾åƒ
        hr_images = []
        for batch_idx, (hr_batch, _) in enumerate(test_loader):
            hr_images.append(hr_batch)
            if len(hr_images) * hr_batch.size(0) >= num_samples:
                break
        
        hr_images = torch.cat(hr_images, dim=0)[:num_samples]
        print(f"åŠ è½½äº† {len(hr_images)} å¼ HRå›¾åƒï¼Œå½¢çŠ¶: {hr_images.shape}")
        
        # åˆ›å»ºLRå›¾åƒ
        lr_images = create_lr_images(hr_images, degradation, sigma_noise, device)
    
    # åˆ›å»ºPnP-Flowæ±‚è§£å™¨
    pnp_solver = PNP_FLOW(model, device, args)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºPnPæ±‚è§£ï¼‰
    test_dataset = torch.utils.data.TensorDataset(hr_images, torch.zeros(len(hr_images)))
    test_loader_pnp = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)
    
    print("å¼€å§‹PnP-Flowæ±‚è§£...")
    
    # ä¸´æ—¶ä¿å­˜åŸå§‹çš„solve_ipæ–¹æ³•å¹¶ä¿®æ”¹å®ƒ
    original_solve_ip = pnp_solver.solve_ip
    
    restored_images = []
    
    def custom_solve_ip(test_loader, degradation, sigma_noise, H_funcs=None):
        H = degradation.H
        H_adj = degradation.H_adj
        args.sigma_noise = sigma_noise
        num_samples_pnp = args.num_samples
        steps, delta = args.steps_pnp, 1 / args.steps_pnp
        
        # ä¼ é€’scale_factoråˆ°å†…éƒ¨å‡½æ•°
        current_sf = scale_factor
        
        if args.noise_type == 'gaussian':
            args.lr_pnp = sigma_noise**2 * args.lr_pnp
            lr = args.lr_pnp
        else:
            raise ValueError('Noise type not supported')
        
        loader = iter(test_loader)
        for batch in range(min(args.max_batch, len(hr_images))):
            (clean_img, _) = next(loader)
            
            # ä½¿ç”¨é¢„å…ˆåˆ›å»ºçš„LRå›¾åƒ
            noisy_img = lr_images[batch:batch+1].to(device)
            clean_img = clean_img.to('cpu')
            
            print(f"\nå¤„ç†ç¬¬ {batch+1}/{min(args.max_batch, len(hr_images))} å¼ å›¾åƒ")
            print(f"LRè¾“å…¥å½¢çŠ¶: {noisy_img.shape}, å€¼åŸŸ: [{noisy_img.min():.3f}, {noisy_img.max():.3f}]")
            
            # åˆå§‹åŒ–ç­–ç•¥é€‰æ‹©
            if current_sf >= 4:
                # å¯¹äº4å€åŠä»¥ä¸Šè¶…åˆ†è¾¨ç‡ï¼šå…ˆç”¨åŒä¸‰æ¬¡æ’å€¼ï¼Œå†ç”¨PnP-Flowä¼˜åŒ–
                print("ä½¿ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼šåŒä¸‰æ¬¡æ’å€¼ + PnP-Flowä¼˜åŒ–")
                x = F.interpolate(noisy_img, scale_factor=current_sf, mode='bicubic', align_corners=False).to(device)
                print(f"åŒä¸‰æ¬¡æ’å€¼åˆå§‹åŒ–å½¢çŠ¶: {x.shape}, å€¼åŸŸ: [{x.min():.3f}, {x.max():.3f}]")
            else:
                # å¯¹äº2xè¶…åˆ†è¾¨ç‡ï¼šä½¿ç”¨åŸå§‹çš„H_adjåˆå§‹åŒ–
                x = H_adj(noisy_img).to(device)
                print(f"H_adjåˆå§‹åŒ–å½¢çŠ¶: {x.shape}, å€¼åŸŸ: [{x.min():.3f}, {x.max():.3f}]")
            
            # PnP-Flowè¿­ä»£
            with torch.no_grad():
                for iteration in range(int(steps)):
                    t1 = torch.ones(len(x), device=device) * delta * iteration
                    lr_t = pnp_solver.learning_rate_strat(lr, t1)
                    
                    # æ•°æ®ä¿çœŸé¡¹æ¢¯åº¦
                    z = x - lr_t * pnp_solver.grad_datafit(x, noisy_img, H, H_adj)
                    
                    # å…ˆéªŒé¡¹ï¼ˆä½¿ç”¨Flow Matchingæ¨¡å‹ï¼‰
                    x_new = torch.zeros_like(x)
                    for _ in range(num_samples_pnp):
                        z_tilde = pnp_solver.interpolation_step(z, t1.view(-1, 1, 1, 1))
                        x_new += pnp_solver.denoiser(z_tilde, t1)
                    
                    x_new /= num_samples_pnp
                    x = x_new
                    
                    if (iteration + 1) % 20 == 0:
                        print(f"  è¿­ä»£ {iteration+1}/{int(steps)}, å€¼åŸŸ: [{x.min():.3f}, {x.max():.3f}]")
            
            restored_img = x.detach().clone()
            restored_images.append(restored_img.cpu())
            
            print(f"æ¢å¤å®Œæˆï¼Œæœ€ç»ˆå€¼åŸŸ: [{restored_img.min():.3f}, {restored_img.max():.3f}]")
    
    # æ›¿æ¢solve_ipæ–¹æ³•
    pnp_solver.solve_ip = custom_solve_ip
    
    # è¿è¡Œæ±‚è§£
    pnp_solver.solve_ip(test_loader_pnp, degradation, sigma_noise)
    
    # æ¢å¤åŸå§‹æ–¹æ³•
    pnp_solver.solve_ip = original_solve_ip
    
    # åˆå¹¶æ¢å¤çš„å›¾åƒ
    restored_images = torch.cat(restored_images, dim=0)
    
    print(f"\n=== PnP-Flowæ±‚è§£å®Œæˆ ===")
    print(f"å¤„ç†äº† {len(restored_images)} å¼ å›¾åƒ")
    
    return hr_images, lr_images, restored_images

def main():
    parser = argparse.ArgumentParser(description='PnP-Flowè¶…åˆ†è¾¨ç‡æµ‹è¯•')
    parser.add_argument('--model_path', type=str, default='./model/cropsr/ot/model_85.pt',
                       help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--num_samples', type=int, default=4,
                       help='æµ‹è¯•æ ·æœ¬æ•°é‡')
    parser.add_argument('--save_images', action='store_true', default=True,
                       help='ä¿å­˜æ ·æœ¬å›¾åƒ')
    parser.add_argument('--scale_factor', type=int, choices=[2, 4, 8], default=2,
                       help='è¶…åˆ†è¾¨ç‡å€æ•° (2x, 4x, 8x)')
    parser.add_argument('--lr_data_path', type=str, default=None,
                       help='ä½åˆ†è¾¨ç‡æ•°æ®è·¯å¾„ (ç”¨äº8xè¶…åˆ†è¾¨ç‡)')
    parser.add_argument('--hr_data_path', type=str, default=None,
                       help='é«˜åˆ†è¾¨ç‡æ•°æ®è·¯å¾„ (ç”¨äº8xè¶…åˆ†è¾¨ç‡)')
    parser.add_argument('--start_idx', type=int, default=0,
                       help='æ•°æ®åŠ è½½èµ·å§‹ç´¢å¼• (ç”¨äºé€‰æ‹©ä¸åŒæ‰¹æ¬¡çš„æ•°æ®)')
    args = parser.parse_args()
    
    try:
        # æ£€æŸ¥GPU
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        if torch.cuda.is_available():
            print(f"GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        
        # æ¸…ç†æ˜¾å­˜
        clear_gpu_memory()
        
        # åŠ è½½æ¨¡å‹
        model, cfg = load_model_and_config(args.model_path, device)
        
        # è¿è¡ŒPnP-Flowæµ‹è¯•
        hr_images, lr_images, restored_images = run_pnp_flow_test(
            model, cfg, device, 
            num_samples=args.num_samples,
            save_dir="./test_results",
            scale_factor=args.scale_factor,
            lr_data_path=args.lr_data_path,
            hr_data_path=args.hr_data_path,
            start_idx=args.start_idx
        )
        
        # ç¡®ä¿ç”¨äºè¯„ä¼°çš„å›¾åƒæ•°é‡ä¸€è‡´
        num_restored = len(restored_images)
        hr_images = hr_images[:num_restored]
        lr_images = lr_images[:num_restored]
        
        # è®¡ç®—åŒä¸‰æ¬¡æ’å€¼åŸºçº¿æŒ‡æ ‡
        baseline_psnr, baseline_ssim, bicubic_images = calculate_baseline_metrics(hr_images, lr_images, cfg)
        
        # è®¡ç®—PnP-Flowå¢å¼ºåçš„æŒ‡æ ‡
        pnpflow_psnr, pnpflow_ssim = calculate_metrics(hr_images, restored_images, cfg)
        
        # ä¿å­˜å¯¹æ¯”å›¾åƒ
        if args.save_images:
            save_comparison_images(hr_images, lr_images, restored_images, bicubic_images, cfg)
        
        # è¯¦ç»†å¯¹æ¯”ç»“æœ
        print("\n" + "="*60)
        if args.scale_factor == 8:
            print("å†œä¸šèˆªæ‹å›¾åƒ8å€è¶…åˆ†è¾¨ç‡æ•ˆæœå¯¹æ¯”")
        else:
            print("å†œä¸šèˆªæ‹å›¾åƒè¶…åˆ†è¾¨ç‡æ•ˆæœå¯¹æ¯”")
        print("="*60)
        print(f"æµ‹è¯•æ ·æœ¬æ•°é‡: {len(hr_images)}")
        actual_sf = hr_images.shape[-1] // lr_images.shape[-1]
        print(f"è¶…åˆ†è¾¨ç‡å€æ•°: {actual_sf}x ({lr_images.shape[-2:][0]}Ã—{lr_images.shape[-2:][1]} â†’ {hr_images.shape[-2:][0]}Ã—{hr_images.shape[-2:][1]})")
        if args.scale_factor == 8:
            print(f"æ•°æ®é›†: CropSRå†œä¸šèˆªæ‹å›¾åƒ (8å€è¶…åˆ†è¾¨ç‡)")
        else:
            print(f"æ•°æ®é›†: CropSRå†œä¸šèˆªæ‹å›¾åƒ")
        print("-" * 60)
        
        print("ğŸ“Š æŒ‡æ ‡å¯¹æ¯”:")
        print(f"{'æ–¹æ³•':<20} {'PSNR (dB)':<12} {'SSIM':<8} {'è¯´æ˜'}")
        print("-" * 60)
        print(f"{'åŒä¸‰æ¬¡æ’å€¼ (åŸºçº¿)':<20} {baseline_psnr:<12.4f} {baseline_ssim:<8.4f} ä¼ ç»Ÿæ’å€¼æ–¹æ³•")
        print(f"{'PnP-Flow (æˆ‘ä»¬çš„)':<20} {pnpflow_psnr:<12.4f} {pnpflow_ssim:<8.4f} Flow Matchingå¢å¼º")
        print(f"{'HRçœŸå®å›¾åƒ':<20} {'âˆ':<12} {'1.0000':<8} ç†æƒ³ä¸Šé™")
        
        print("-" * 60)
        print("ğŸ“ˆ æ”¹è¿›å¹…åº¦:")
        psnr_improvement = pnpflow_psnr - baseline_psnr
        ssim_improvement = pnpflow_ssim - baseline_ssim
        print(f"PSNR æå‡: {psnr_improvement:+.4f} dB ({psnr_improvement/baseline_psnr*100:+.2f}%)")
        print(f"SSIM æå‡: {ssim_improvement:+.4f} ({ssim_improvement/baseline_ssim*100:+.2f}%)")
        
        print("-" * 60)
        print("ğŸ¯ ç»“è®º:")
        if psnr_improvement > 0 and ssim_improvement > 0:
            if args.scale_factor == 8:
                print("âœ… PnP-Flowåœ¨8å€è¶…åˆ†è¾¨ç‡è¿™ä¸€æå…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•")
                print("âœ… è¯æ˜äº†Flow Matchingå…ˆéªŒåœ¨æé«˜å€æ•°è¶…åˆ†è¾¨ç‡ä¸­çš„æœ‰æ•ˆæ€§")
                print("âœ… ä¸ºå†œä¸šèˆªæ‹å›¾åƒçš„ç²¾ç»†åˆ†ææä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘")
            else:
                print("âœ… PnP-Flowæ–¹æ³•åœ¨PSNRå’ŒSSIMä¸Šéƒ½ä¼˜äºåŒä¸‰æ¬¡æ’å€¼åŸºçº¿")
                print("âœ… è¯æ˜äº†Flow Matchingå…ˆéªŒåœ¨å†œä¸šå›¾åƒè¶…åˆ†è¾¨ç‡ä¸­çš„æœ‰æ•ˆæ€§")
        elif psnr_improvement > 0:
            print("âœ… PnP-Flowåœ¨PSNRä¸Šä¼˜äºåŸºçº¿ï¼Œä½†SSIMæå‡æœ‰é™")
        elif ssim_improvement > 0:
            print("âœ… PnP-Flowåœ¨SSIMä¸Šä¼˜äºåŸºçº¿ï¼Œä½†PSNRæå‡æœ‰é™")
        else:
            if args.scale_factor == 8:
                print("âš ï¸  8å€è¶…åˆ†è¾¨ç‡æ˜¯æå…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜å‚æ•°")
            else:
                print("âš ï¸  PnP-Flowæ–¹æ³•éœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")
            
        print(f"\nğŸ“ å¯¹æ¯”å›¾åƒå·²ä¿å­˜åˆ° ./test_results/ ç›®å½•")
        print("   å¯ä»¥ç›´è§‚æ¯”è¾ƒå››ç§å›¾åƒçš„è§†è§‰æ•ˆæœ")
        print("="*60)
        
    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 