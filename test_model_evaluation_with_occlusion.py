#!/usr/bin/env python3
"""
ä½¿ç”¨PnP-Flowæ–¹æ³•æµ‹è¯•å¸¦é®æŒ¡çš„CropSRè¶…åˆ†è¾¨ç‡ä»»åŠ¡
æµ‹è¯•åœ¨æœ‰éšæœºæ–¹å—é®æŒ¡æƒ…å†µä¸‹çš„å›¾åƒæ¢å¤èƒ½åŠ›
åŸºäºé¢„è®­ç»ƒçš„Flow Matchingæ¨¡å‹è¿›è¡Œæ¡ä»¶å›¾åƒæ¢å¤
"""

import torch
import numpy as np
import sys
import os
import argparse
from PIL import Image
import torch.nn.functional as F
from time import perf_counter
import random

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')
from pnpflow.utils import define_model, load_cfg_from_cfg_file, postprocess
from pnpflow.train_flow_matching import FLOW_MATCHING
from pnpflow.dataloaders import DataLoaders
from pnpflow.degradations import Superresolution
from pnpflow.methods.pnp_flow import PNP_FLOW
import pnpflow.utils as utils

class OccludedSuperresolution:
    """å¸¦é®æŒ¡çš„è¶…åˆ†è¾¨ç‡é™è´¨ç±»ï¼Œé¿å…åˆ›å»ºå·¨å¤§çš„é™é‡‡æ ·çŸ©é˜µ"""
    def __init__(self, sf, dim_image, device="cuda", occlusion_params=None):
        self.sf = sf
        self.device = device
        self.dim_image = dim_image
        self.occlusion_params = occlusion_params or {
            'num_blocks': 5,      # é®æŒ¡æ–¹å—æ•°é‡
            'min_size': 20,       # æ–¹å—æœ€å°å°ºå¯¸
            'max_size': 60,       # æ–¹å—æœ€å¤§å°ºå¯¸
            'intensity': 0.0      # é®æŒ¡å¼ºåº¦ (0.0=é»‘è‰², 1.0=ç™½è‰², 0.5=ç°è‰²)
        }
        
    def add_random_occlusion(self, x):
        """æ·»åŠ éšæœºæ–¹å—é®æŒ¡"""
        batch_size, channels, height, width = x.shape
        occluded_x = x.clone()
        
        # ä¸ºæ¯ä¸ªå›¾åƒæ·»åŠ é®æŒ¡
        for b in range(batch_size):
            num_blocks = self.occlusion_params['num_blocks']
            min_size = self.occlusion_params['min_size']
            max_size = self.occlusion_params['max_size']
            intensity = self.occlusion_params['intensity']
            
            for _ in range(num_blocks):
                # éšæœºé€‰æ‹©æ–¹å—å°ºå¯¸
                block_w = random.randint(min_size, min(max_size, width))
                block_h = random.randint(min_size, min(max_size, height))
                
                # éšæœºé€‰æ‹©æ–¹å—ä½ç½®
                start_x = random.randint(0, width - block_w)
                start_y = random.randint(0, height - block_h)
                
                # åº”ç”¨é®æŒ¡
                occluded_x[b, :, start_y:start_y+block_h, start_x:start_x+block_w] = intensity
        
        return occluded_x
    
    def H(self, x):
        """é™è´¨æ“ä½œï¼šHR -> é®æŒ¡ -> LRï¼Œä½¿ç”¨é«˜æ•ˆçš„æ’å€¼æ–¹æ³•"""
        # å…ˆæ·»åŠ é®æŒ¡
        occluded_x = self.add_random_occlusion(x)
        # ä½¿ç”¨æ’å€¼è¿›è¡Œé™é‡‡æ ·ï¼Œé¿å…å·¨å¤§çŸ©é˜µ
        return F.interpolate(occluded_x, scale_factor=1/self.sf, mode='bilinear', align_corners=False)
    
    def H_adj(self, x):
        """ä¸Šé‡‡æ ·æ“ä½œï¼šLR -> HRï¼Œä½¿ç”¨åŒä¸‰æ¬¡æ’å€¼"""
        return F.interpolate(x, scale_factor=self.sf, mode='bicubic', align_corners=False)

class Args:
    """é…ç½®ç±»ï¼Œæ¨¡æ‹Ÿargparseå‚æ•°"""
    def __init__(self, cfg):
        # ä»é…ç½®æ–‡ä»¶å¤åˆ¶åŸºæœ¬å‚æ•°
        for key, value in cfg.items():
            setattr(self, key, value)
        
        # PnP-Flowç‰¹å®šå‚æ•° (æŒ‰ç…§main.pyä¸­çš„è®¾ç½®)
        self.method = 'pnp_flow'
        self.problem = 'superresolution'  # ä½¿ç”¨æ ‡å‡†è¶…åˆ†è¾¨ç‡é—®é¢˜
        self.noise_type = 'gaussian'
        self.sigma_noise = 0.05          # æŒ‰ç…§main.pyä¸­gaussianå™ªå£°çš„æ ‡å‡†è®¾ç½®
        self.max_batch = 8               # æµ‹è¯•æ ·æœ¬æ•°é‡
        self.batch_size_ip = 1           # æ¯æ¬¡å¤„ç†ä¸€å¼ å›¾åƒ
        self.eval_split = 'test'
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½æ–¹æ³•é…ç½®
        method_config_file = cfg.root + 'config/method_config/{}.yaml'.format(self.method)
        try:
            method_cfg = load_cfg_from_cfg_file(method_config_file)
            # æ›´æ–°é…ç½®
            for key, value in method_cfg.items():
                setattr(self, key, value)
        except FileNotFoundError:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æ–¹æ³•é…ç½®æ–‡ä»¶ {method_config_file}ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
                        # é»˜è®¤PnP-Flowç®—æ³•å‚æ•°
            self.steps_pnp = 200
            self.lr_pnp = 1.5
            self.num_samples = 3
            self.gamma_style = 'alpha_1_minus_t'
            self.alpha = 1.0
        
        # ä¿å­˜å’Œè®¡ç®—é€‰é¡¹
        self.save_results = True
        self.compute_time = False
        self.compute_memory = False
        
        # åˆ›å»ºæ–¹æ³•é…ç½®å­—å…¸
        self.dict_cfg_method = {}
        try:
            method_cfg = load_cfg_from_cfg_file(method_config_file)
            for key in method_cfg.keys():
                self.dict_cfg_method[key] = getattr(self, key)
        except:
            self.dict_cfg_method = {
                'steps_pnp': getattr(self, 'steps_pnp', 100),
                'lr_pnp': getattr(self, 'lr_pnp', 1.0),
                'num_samples': getattr(self, 'num_samples', 3),
                'gamma_style': getattr(self, 'gamma_style', 'constant')
            }

def clear_gpu_memory():
    """æ¸…ç†GPUæ˜¾å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print("GPUæ˜¾å­˜å·²æ¸…ç†")

def load_model_and_config(model_path, device):
    """åŠ è½½æ¨¡å‹å’Œé…ç½®"""
    print("=== åŠ è½½é…ç½®å’Œæ¨¡å‹ ===")
    
    # åŠ è½½é…ç½®
    cfg = load_cfg_from_cfg_file('./config/main_config.yaml')
    dataset_config = cfg.root + f'config/dataset_config/{cfg.dataset}.yaml'
    cfg.update(load_cfg_from_cfg_file(dataset_config))
    
    print(f"æ•°æ®é›†: {cfg.dataset}")
    print(f"å›¾åƒå°ºå¯¸: {cfg.dim_image}x{cfg.dim_image}")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model, state = define_model(cfg)
    model = model.to(device)
    
    # åŠ è½½æƒé‡
    if os.path.exists(model_path):
        print(f"åŠ è½½æ¨¡å‹: {model_path}")
        model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))
        model.eval()
        print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())/1e6:.2f}M")
    else:
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    return model, cfg

def create_occluded_lr_images(hr_images, degradation, sigma_noise, device, seed=42):
    """åˆ›å»ºå¸¦é®æŒ¡çš„LRå›¾åƒ"""
    print("=== åˆ›å»ºå¸¦é®æŒ¡çš„LRå›¾åƒ ===")
    
    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
    torch.manual_seed(seed)
    random.seed(seed)
    
    lr_images = []
    occluded_hr_images = []  # ä¿å­˜é®æŒ¡åçš„HRå›¾åƒç”¨äºå¯è§†åŒ–
    lr_masks = []           # ä¿å­˜LRé®æŒ¡æ©ç 
    
    for i, hr_img in enumerate(hr_images):
        hr_single = hr_img.unsqueeze(0).to(device)
        
        # åˆ›å»ºHRé®æŒ¡æ©ç 
        mask_hr = torch.ones_like(hr_single[:, :1, :, :])  # å•é€šé“æ©ç 
        num_blocks = degradation.occlusion_params['num_blocks']
        min_size = degradation.occlusion_params['min_size']
        max_size = degradation.occlusion_params['max_size']
        intensity = degradation.occlusion_params['intensity']
        
        # æ‰‹åŠ¨æ·»åŠ é®æŒ¡å¹¶åŒæ­¥æ›´æ–°æ©ç 
        occluded_hr = hr_single.clone()
        _, _, H, W = hr_single.shape
        for _ in range(num_blocks):
            block_w = random.randint(min_size, min(max_size, W))
            block_h = random.randint(min_size, min(max_size, H))
            start_x = random.randint(0, W - block_w)
            start_y = random.randint(0, H - block_h)
            
            occluded_hr[:, :, start_y:start_y+block_h, start_x:start_x+block_w] = intensity
            mask_hr[:, :, start_y:start_y+block_h, start_x:start_x+block_w] = 0.0
        
        # HR->LR é™é‡‡æ ·
        lr_single = F.interpolate(occluded_hr, scale_factor=1/degradation.sf, mode='bilinear', align_corners=False)
        lr_mask_single = F.interpolate(mask_hr, scale_factor=1/degradation.sf, mode='nearest')
        
        # æ·»åŠ å™ªå£°
        if sigma_noise > 0:
            lr_single += torch.randn_like(lr_single) * sigma_noise
        
        lr_images.append(lr_single.cpu())
        occluded_hr_images.append(occluded_hr.cpu())
        lr_masks.append(lr_mask_single.cpu())
        
        print(f"åˆ›å»ºç¬¬ {i+1} å¼ å¸¦é®æŒ¡çš„LRå›¾åƒ")
        print(f"  HRå½¢çŠ¶: {hr_single.shape}, å€¼åŸŸ: [{hr_single.min():.3f}, {hr_single.max():.3f}]")
        print(f"  é®æŒ¡HRå½¢çŠ¶: {occluded_hr.shape}, å€¼åŸŸ: [{occluded_hr.min():.3f}, {occluded_hr.max():.3f}]")
        print(f"  LRå½¢çŠ¶: {lr_single.shape}, å€¼åŸŸ: [{lr_single.min():.3f}, {lr_single.max():.3f}]")
    
    return torch.cat(lr_images, dim=0), torch.cat(occluded_hr_images, dim=0), torch.cat(lr_masks, dim=0)

def save_occlusion_comparison_images(hr_images, occluded_hr_images, lr_images, restored_images, 
                                   bicubic_images, cfg, save_dir="./test_results_occlusion"):
    """ä¿å­˜é®æŒ¡å¯¹æ¯”å›¾åƒï¼šHRçœŸå®ã€é®æŒ¡HRã€LRè¾“å…¥ã€åŒä¸‰æ¬¡æ’å€¼ã€PnP-Flowæ¢å¤"""
    print(f"=== ä¿å­˜é®æŒ¡å¯¹æ¯”å›¾åƒåˆ° {save_dir} ===")
    os.makedirs(save_dir, exist_ok=True)
    
    # åå¤„ç†å›¾åƒç”¨äºä¿å­˜
    hr_processed = postprocess(hr_images, cfg)
    occluded_hr_processed = postprocess(occluded_hr_images, cfg)
    lr_processed = postprocess(lr_images, cfg)
    restored_processed = postprocess(restored_images, cfg)
    bicubic_processed = postprocess(bicubic_images, cfg)
    
    # ç¡®ä¿å€¼åŸŸåœ¨[0,1]å¹¶è½¬æ¢ä¸ºuint8
    hr_processed = torch.clamp(hr_processed, 0, 1)
    occluded_hr_processed = torch.clamp(occluded_hr_processed, 0, 1)
    lr_processed = torch.clamp(lr_processed, 0, 1)
    restored_processed = torch.clamp(restored_processed, 0, 1)
    bicubic_processed = torch.clamp(bicubic_processed, 0, 1)
    
    for i in range(len(hr_images)):
        # HRçœŸå®å›¾åƒ
        hr_img = (hr_processed[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        Image.fromarray(hr_img).save(f"{save_dir}/01_HR_GT_{i:02d}.png")
        
        # é®æŒ¡åçš„HRå›¾åƒ
        occluded_hr_img = (occluded_hr_processed[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        Image.fromarray(occluded_hr_img).save(f"{save_dir}/02_HR_Occluded_{i:02d}.png")
        
        # LRè¾“å…¥å›¾åƒ
        lr_img = (lr_processed[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        Image.fromarray(lr_img).save(f"{save_dir}/03_LR_Input_{i:02d}.png")
        
        # åŒä¸‰æ¬¡æ’å€¼ç»“æœ
        bicubic_img = (bicubic_processed[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        Image.fromarray(bicubic_img).save(f"{save_dir}/04_Bicubic_Upsampled_{i:02d}.png")
        
        # PnP-Flowæ¢å¤ç»“æœ
        restored_img = (restored_processed[i].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)
        Image.fromarray(restored_img).save(f"{save_dir}/05_Restored_PnPFlow_{i:02d}.png")
        
        print(f"å·²ä¿å­˜ç¬¬ {i+1} ç»„é®æŒ¡å¯¹æ¯”å›¾åƒ")
    
    print("æ–‡ä»¶å‘½åè§„åˆ™:")
    print("  01_HR_GT_XX.png: é«˜åˆ†è¾¨ç‡çœŸå®å›¾åƒ (Ground Truth)")
    print("  02_HR_Occluded_XX.png: é®æŒ¡åçš„é«˜åˆ†è¾¨ç‡å›¾åƒ")
    print("  03_LR_Input_XX.png: ä½åˆ†è¾¨ç‡è¾“å…¥å›¾åƒ")
    print("  04_Bicubic_Upsampled_XX.png: åŒä¸‰æ¬¡æ’å€¼ä¸Šé‡‡æ ·ç»“æœ")
    print("  05_Restored_PnPFlow_XX.png: PnP-Flowæ¢å¤çš„å›¾åƒ")

def calculate_occlusion_metrics(hr_images, restored_images, occluded_hr_images, cfg):
    """è®¡ç®—é®æŒ¡æ¢å¤çš„è¯„ä¼°æŒ‡æ ‡"""
    print("=== è®¡ç®—é®æŒ¡æ¢å¤è¯„ä¼°æŒ‡æ ‡ ===")
    
    # åå¤„ç†åˆ°[0,1]èŒƒå›´ç”¨äºæŒ‡æ ‡è®¡ç®—
    hr_processed = postprocess(hr_images, cfg)
    restored_processed = postprocess(restored_images, cfg)
    occluded_hr_processed = postprocess(occluded_hr_images, cfg)
    
    # ç¡®ä¿å€¼åŸŸåœ¨[0,1]
    hr_processed = torch.clamp(hr_processed, 0, 1)
    restored_processed = torch.clamp(restored_processed, 0, 1)
    occluded_hr_processed = torch.clamp(occluded_hr_processed, 0, 1)
    
    # è®¡ç®—æ¢å¤åvsçœŸå®HRçš„PSNR/SSIM
    mse = torch.mean((hr_processed - restored_processed) ** 2)
    psnr_restored = 20 * torch.log10(1.0 / torch.sqrt(mse))
    
    # è®¡ç®—é®æŒ¡HR vs çœŸå®HRçš„PSNR/SSIMï¼ˆä½œä¸ºåŸºçº¿å‚è€ƒï¼‰
    mse_occluded = torch.mean((hr_processed - occluded_hr_processed) ** 2)
    psnr_occluded = 20 * torch.log10(1.0 / torch.sqrt(mse_occluded))
    
    print(f"é®æŒ¡å›¾åƒ vs çœŸå®å›¾åƒ PSNR: {psnr_occluded.item():.4f} dB")
    print(f"æ¢å¤å›¾åƒ vs çœŸå®å›¾åƒ PSNR: {psnr_restored.item():.4f} dB")
    
    # è®¡ç®—SSIM
    def ssim_single_channel(img1, img2):
        mu1 = F.avg_pool2d(img1, 3, 1, 1)
        mu2 = F.avg_pool2d(img2, 3, 1, 1)
        mu1_sq = mu1.pow(2)
        mu2_sq = mu2.pow(2)
        mu1_mu2 = mu1 * mu2
        
        sigma1_sq = F.avg_pool2d(img1 * img1, 3, 1, 1) - mu1_sq
        sigma2_sq = F.avg_pool2d(img2 * img2, 3, 1, 1) - mu2_sq
        sigma12 = F.avg_pool2d(img1 * img2, 3, 1, 1) - mu1_mu2
        
        C1 = 0.01 ** 2
        C2 = 0.03 ** 2
        
        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
        return ssim_map.mean()
    
    # å¯¹æ¯ä¸ªé€šé“è®¡ç®—SSIM
    ssim_restored = []
    ssim_occluded = []
    for c in range(hr_processed.shape[1]):
        ssim_r = ssim_single_channel(hr_processed[:, c:c+1], restored_processed[:, c:c+1])
        ssim_o = ssim_single_channel(hr_processed[:, c:c+1], occluded_hr_processed[:, c:c+1])
        ssim_restored.append(ssim_r)
        ssim_occluded.append(ssim_o)
    
    ssim_restored = torch.mean(torch.stack(ssim_restored))
    ssim_occluded = torch.mean(torch.stack(ssim_occluded))
    
    print(f"é®æŒ¡å›¾åƒ vs çœŸå®å›¾åƒ SSIM: {ssim_occluded.item():.4f}")
    print(f"æ¢å¤å›¾åƒ vs çœŸå®å›¾åƒ SSIM: {ssim_restored.item():.4f}")
    
    return (psnr_occluded.item(), ssim_occluded.item(), 
            psnr_restored.item(), ssim_restored.item())

def calculate_baseline_metrics(hr_images, lr_images, cfg):
    """è®¡ç®—LRåŒä¸‰æ¬¡æ’å€¼ä¸Šé‡‡æ ·çš„åŸºçº¿æŒ‡æ ‡"""
    print("=== è®¡ç®—åŒä¸‰æ¬¡æ’å€¼åŸºçº¿æŒ‡æ ‡ ===")
    
    # å¯¹LRå›¾åƒè¿›è¡ŒåŒä¸‰æ¬¡æ’å€¼ä¸Šé‡‡æ ·
    sf = hr_images.shape[-1] // lr_images.shape[-1]  # è®¡ç®—æ”¾å¤§å€æ•°
    bicubic_upsampled = F.interpolate(lr_images, scale_factor=sf, mode='bicubic', align_corners=False)
    
    # åå¤„ç†åˆ°[0,1]èŒƒå›´
    hr_processed = postprocess(hr_images, cfg)
    bicubic_processed = postprocess(bicubic_upsampled, cfg)
    
    # ç¡®ä¿å€¼åŸŸåœ¨[0,1]
    hr_processed = torch.clamp(hr_processed, 0, 1)
    bicubic_processed = torch.clamp(bicubic_processed, 0, 1)
    
    # è®¡ç®—PSNR
    mse = torch.mean((hr_processed - bicubic_processed) ** 2)
    psnr = 20 * torch.log10(1.0 / torch.sqrt(mse))
    print(f"åŒä¸‰æ¬¡æ’å€¼ PSNR: {psnr.item():.4f} dB")
    
    # è®¡ç®—SSIM
    def ssim_single_channel(img1, img2):
        mu1 = F.avg_pool2d(img1, 3, 1, 1)
        mu2 = F.avg_pool2d(img2, 3, 1, 1)
        mu1_sq = mu1.pow(2)
        mu2_sq = mu2.pow(2)
        mu1_mu2 = mu1 * mu2
        
        sigma1_sq = F.avg_pool2d(img1 * img1, 3, 1, 1) - mu1_sq
        sigma2_sq = F.avg_pool2d(img2 * img2, 3, 1, 1) - mu2_sq
        sigma12 = F.avg_pool2d(img1 * img2, 3, 1, 1) - mu1_mu2
        
        C1 = 0.01 ** 2
        C2 = 0.03 ** 2
        
        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))
        return ssim_map.mean()
    
    # å¯¹æ¯ä¸ªé€šé“è®¡ç®—SSIM
    ssim_values = []
    for c in range(hr_processed.shape[1]):
        ssim_c = ssim_single_channel(hr_processed[:, c:c+1], bicubic_processed[:, c:c+1])
        ssim_values.append(ssim_c)
    
    ssim = torch.mean(torch.stack(ssim_values))
    print(f"åŒä¸‰æ¬¡æ’å€¼ SSIM: {ssim.item():.4f}")
    
    return psnr.item(), ssim.item(), bicubic_upsampled

def run_pnp_flow_occlusion_test(model, cfg, device, num_samples=8, save_dir="./test_results_occlusion", 
                                occlusion_params=None):
    """è¿è¡ŒPnP-Flowé®æŒ¡è¶…åˆ†è¾¨ç‡æµ‹è¯•"""
    print("=== å¼€å§‹PnP-Flowé®æŒ¡è¶…åˆ†è¾¨ç‡æµ‹è¯• ===")
    
    # åˆ›å»ºå‚æ•°å¯¹è±¡
    args = Args(cfg)
    args.save_path = save_dir
    # è°ƒæ•´å…³é”®è¶…å‚æ•°ä»¥å¢å¼ºå…ˆéªŒä½œç”¨
    args.steps_pnp = 100
    args.num_samples = 3
    args.lr_pnp = 1.0
    
    # æŒ‰ç…§main.pyä¸­çš„è®¾ç½®ç¡®å®šè¶…åˆ†è¾¨ç‡å€æ•°
    if cfg.dim_image == 128:
        sf = 2
        print('Superresolution with scale factor 2')
    elif cfg.dim_image == 256:
        sf = 4
        print('Superresolution with scale factor 4')
    elif cfg.dim_image == 512:
        sf = 2  # å¯¹äº512ç»´å›¾åƒï¼Œæˆ‘ä»¬æµ‹è¯•2xè¶…åˆ†è¾¨ç‡
        print('Superresolution with scale factor 2 (512->256->512)')
    else:
        sf = 2  # é»˜è®¤2x
        print(f'Superresolution with scale factor 2 (default for dim_image={cfg.dim_image})')
    
    # è®¾ç½®é®æŒ¡å‚æ•°
    if occlusion_params is None:
        occlusion_params = {
            'num_blocks': 5,      # é®æŒ¡æ–¹å—æ•°é‡
            'min_size': 30,       # æ–¹å—æœ€å°å°ºå¯¸
            'max_size': 80,       # æ–¹å—æœ€å¤§å°ºå¯¸
            'intensity': 0.0      # é®æŒ¡å¼ºåº¦ (é»‘è‰²é®æŒ¡)
        }
    
    print(f"é®æŒ¡å‚æ•°: {occlusion_params}")
    print(f"å™ªå£°å¼ºåº¦: {args.sigma_noise} (gaussian)")
    
    # åˆ›å»ºå¸¦é®æŒ¡çš„é™è´¨æ¨¡å‹
    degradation = OccludedSuperresolution(sf, cfg.dim_image, device, occlusion_params)
    sigma_noise = args.sigma_noise
    
    # ä»æ•°æ®é›†åŠ è½½æµ‹è¯•æ•°æ®
    print("ä»æ•°æ®é›†åŠ è½½æµ‹è¯•æ•°æ®...")
    data_loaders = DataLoaders(cfg.dataset, num_samples, num_samples).load_data()
    test_loader = data_loaders['test']
    
    # è·å–HRå›¾åƒ
    hr_images = []
    for batch_idx, (hr_batch, _) in enumerate(test_loader):
        hr_images.append(hr_batch)
        if len(hr_images) * hr_batch.size(0) >= num_samples:
            break
    
    hr_images = torch.cat(hr_images, dim=0)[:num_samples]
    print(f"åŠ è½½äº† {len(hr_images)} å¼ HRå›¾åƒï¼Œå½¢çŠ¶: {hr_images.shape}")
    
    # åˆ›å»ºå¸¦é®æŒ¡çš„LRå›¾åƒ
    lr_images, occluded_hr_images, lr_masks = create_occluded_lr_images(hr_images, degradation, sigma_noise, device)
    
    # åˆ›å»ºPnP-Flowæ±‚è§£å™¨
    pnp_solver = PNP_FLOW(model, device, args)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆç”¨äºPnPæ±‚è§£ï¼‰
    test_dataset = torch.utils.data.TensorDataset(hr_images, torch.zeros(len(hr_images)))
    test_loader_pnp = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)
    
    print("å¼€å§‹PnP-Flowæ±‚è§£...")
    
    # ä¸´æ—¶ä¿å­˜åŸå§‹çš„solve_ipæ–¹æ³•å¹¶ä¿®æ”¹å®ƒ
    original_solve_ip = pnp_solver.solve_ip
    
    restored_images = []
    
    def custom_solve_ip(test_loader, degradation, sigma_noise, H_funcs=None):
        H = degradation.H
        H_adj = degradation.H_adj
        args.sigma_noise = sigma_noise
        num_samples_pnp = args.num_samples
        steps, delta = args.steps_pnp, 1 / args.steps_pnp
        
        # æŒ‰ç…§main.pyä¸­çš„å­¦ä¹ ç‡è®¾ç½®
        if args.noise_type == 'gaussian':
            lr = sigma_noise**2 * args.lr_pnp
            print(f"ä½¿ç”¨å­¦ä¹ ç‡: {lr} (åŸºç¡€lr: {args.lr_pnp}, sigma_noise: {sigma_noise})")
        else:
            raise ValueError('Noise type not supported')
        
        loader = iter(test_loader)
        for batch in range(min(args.max_batch, len(hr_images))):
            (clean_img, _) = next(loader)
            
            noisy_img = lr_images[batch:batch+1].to(device)
            mask = lr_masks[batch:batch+1].to(device)
            clean_img = clean_img.to('cpu')
            
            print(f"\nå¤„ç†ç¬¬ {batch+1}/{min(args.max_batch, len(hr_images))} å¼ å›¾åƒ")
            print(f"LRè¾“å…¥å½¢çŠ¶: {noisy_img.shape}, å€¼åŸŸ: [{noisy_img.min():.3f}, {noisy_img.max():.3f}]")
            print(f"ç®—æ³•å‚æ•°: steps={steps}, lr={lr}, num_samples={num_samples_pnp}")
            
            # åˆå§‹åŒ–ï¼šä½¿ç”¨æ ‡å‡†çš„H_adj
            x = H_adj(noisy_img).to(device)
            print(f"åˆå§‹åŒ–å½¢çŠ¶: {x.shape}, å€¼åŸŸ: [{x.min():.3f}, {x.max():.3f}]")
            
            # PnP-Flowè¿­ä»£
            with torch.no_grad():
                for iteration in range(int(steps)):
                    t1 = torch.ones(len(x), device=device) * delta * iteration
                    lr_t = pnp_solver.learning_rate_strat(lr, t1)
                    
                    # ä»…åœ¨éé®æŒ¡åƒç´ è®¡ç®—æ¢¯åº¦
                    residual = H(x) - noisy_img
                    residual = residual * mask  # å¿½ç•¥é®æŒ¡åƒç´ 
                    z = x - lr_t * H_adj(residual) / (sigma_noise**2)
                    
                    # å…ˆéªŒé¡¹ï¼ˆä½¿ç”¨Flow Matchingæ¨¡å‹ï¼‰
                    x_new = torch.zeros_like(x)
                    for _ in range(num_samples_pnp):
                        z_tilde = pnp_solver.interpolation_step(z, t1.view(-1, 1, 1, 1))
                        x_new += pnp_solver.denoiser(z_tilde, t1)
                    
                    x_new /= num_samples_pnp
                    x = x_new
                    
                    # æ‰“å°è¿›åº¦
                    print_interval = max(1, steps // 5)  # æ‰“å°5æ¬¡è¿›åº¦
                    if (iteration + 1) % print_interval == 0 or iteration == 0:
                        print(f"  è¿­ä»£ {iteration+1}/{int(steps)}, å€¼åŸŸ: [{x.min():.3f}, {x.max():.3f}]")
            
            restored_img = x.detach().clone()
            restored_images.append(restored_img.cpu())
            
            print(f"æ¢å¤å®Œæˆï¼Œæœ€ç»ˆå€¼åŸŸ: [{restored_img.min():.3f}, {restored_img.max():.3f}]")
    
    # æ›¿æ¢solve_ipæ–¹æ³•
    pnp_solver.solve_ip = custom_solve_ip
    
    # è¿è¡Œæ±‚è§£
    pnp_solver.solve_ip(test_loader_pnp, degradation, sigma_noise)
    
    # æ¢å¤åŸå§‹æ–¹æ³•
    pnp_solver.solve_ip = original_solve_ip
    
    # åˆå¹¶æ¢å¤çš„å›¾åƒ
    restored_images = torch.cat(restored_images, dim=0)
    
    print(f"\n=== PnP-Flowé®æŒ¡æ¢å¤å®Œæˆ ===")
    print(f"å¤„ç†äº† {len(restored_images)} å¼ å›¾åƒ")
    
    return hr_images, occluded_hr_images, lr_images, restored_images

def main():
    parser = argparse.ArgumentParser(description='PnP-Flowå¸¦é®æŒ¡è¶…åˆ†è¾¨ç‡æµ‹è¯•')
    parser.add_argument('--model_path', type=str, default='./model/cropsr/ot/model_85.pt',
                       help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--num_samples', type=int, default=8,
                       help='æµ‹è¯•æ ·æœ¬æ•°é‡')
    parser.add_argument('--save_images', action='store_true', default=True,
                       help='ä¿å­˜æ ·æœ¬å›¾åƒ')
    parser.add_argument('--num_blocks', type=int, default=5,
                       help='é®æŒ¡æ–¹å—æ•°é‡')
    parser.add_argument('--min_size', type=int, default=30,
                       help='é®æŒ¡æ–¹å—æœ€å°å°ºå¯¸')
    parser.add_argument('--max_size', type=int, default=80,
                       help='é®æŒ¡æ–¹å—æœ€å¤§å°ºå¯¸')
    parser.add_argument('--intensity', type=float, default=0.0,
                       help='é®æŒ¡å¼ºåº¦ (0.0=é»‘è‰², 1.0=ç™½è‰², 0.5=ç°è‰²)')
    args = parser.parse_args()
    
    try:
        # æ£€æŸ¥GPU
        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        if torch.cuda.is_available():
            print(f"GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        
        # æ¸…ç†æ˜¾å­˜
        clear_gpu_memory()
        
        # åŠ è½½æ¨¡å‹
        model, cfg = load_model_and_config(args.model_path, device)
        
        # è®¾ç½®é®æŒ¡å‚æ•°
        occlusion_params = {
            'num_blocks': args.num_blocks,
            'min_size': args.min_size,
            'max_size': args.max_size,
            'intensity': args.intensity
        }
        
        # è¿è¡ŒPnP-Flowé®æŒ¡æµ‹è¯•
        hr_images, occluded_hr_images, lr_images, restored_images = run_pnp_flow_occlusion_test(
            model, cfg, device, 
            num_samples=args.num_samples,
            save_dir="./test_results_occlusion",
            occlusion_params=occlusion_params
        )
        
        # è®¡ç®—åŒä¸‰æ¬¡æ’å€¼åŸºçº¿æŒ‡æ ‡
        baseline_psnr, baseline_ssim, bicubic_images = calculate_baseline_metrics(hr_images, lr_images, cfg)
        
        # è®¡ç®—é®æŒ¡æ¢å¤æŒ‡æ ‡
        psnr_occluded, ssim_occluded, psnr_restored, ssim_restored = calculate_occlusion_metrics(
            hr_images, restored_images, occluded_hr_images, cfg)
        
        # ä¿å­˜å¯¹æ¯”å›¾åƒ
        if args.save_images:
            save_occlusion_comparison_images(hr_images, occluded_hr_images, lr_images, restored_images, bicubic_images, cfg)
        
        # è¯¦ç»†å¯¹æ¯”ç»“æœ
        print("\n" + "="*70)
        print("å†œä¸šèˆªæ‹å›¾åƒå¸¦é®æŒ¡2å€è¶…åˆ†è¾¨ç‡æ•ˆæœå¯¹æ¯”")
        print("="*70)
        print(f"æµ‹è¯•æ ·æœ¬æ•°é‡: {len(hr_images)}")
        print(f"è¶…åˆ†è¾¨ç‡å€æ•°: 2x ({lr_images.shape[-2:][0]}Ã—{lr_images.shape[-2:][1]} â†’ {hr_images.shape[-2:][0]}Ã—{hr_images.shape[-2:][1]})")
        print(f"æ•°æ®é›†: CropSRå†œä¸šèˆªæ‹å›¾åƒ")
        print(f"é®æŒ¡å‚æ•°: {occlusion_params}")
        print("-" * 70)
        
        print("ğŸ“Š æŒ‡æ ‡å¯¹æ¯”:")
        print(f"{'æ–¹æ³•':<25} {'PSNR (dB)':<12} {'SSIM':<8} {'è¯´æ˜'}")
        print("-" * 70)
        print(f"{'é®æŒ¡å›¾åƒ (æŸå¤±åŸºçº¿)':<25} {psnr_occluded:<12.4f} {ssim_occluded:<8.4f} é®æŒ¡é€ æˆçš„æŸå¤±")
        print(f"{'åŒä¸‰æ¬¡æ’å€¼':<25} {baseline_psnr:<12.4f} {baseline_ssim:<8.4f} ä¼ ç»Ÿæ’å€¼æ–¹æ³•")
        print(f"{'PnP-Flow (æˆ‘ä»¬çš„)':<25} {psnr_restored:<12.4f} {ssim_restored:<8.4f} Flow Matchingæ¢å¤")
        print(f"{'HRçœŸå®å›¾åƒ':<25} {'âˆ':<12} {'1.0000':<8} ç†æƒ³ä¸Šé™")
        
        print("-" * 70)
        print("ğŸ“ˆ é®æŒ¡æ¢å¤èƒ½åŠ›:")
        psnr_recovery = psnr_restored - psnr_occluded
        ssim_recovery = ssim_restored - ssim_occluded
        print(f"PSNR æ¢å¤: {psnr_recovery:+.4f} dB ({psnr_recovery/abs(psnr_occluded)*100:+.2f}%)")
        print(f"SSIM æ¢å¤: {ssim_recovery:+.4f} ({ssim_recovery/ssim_occluded*100:+.2f}%)")
        
        print("\nğŸ“ˆ ç›¸å¯¹äºåŒä¸‰æ¬¡æ’å€¼çš„æ”¹è¿›:")
        psnr_improvement = psnr_restored - baseline_psnr
        ssim_improvement = ssim_restored - baseline_ssim
        print(f"PSNR æå‡: {psnr_improvement:+.4f} dB ({psnr_improvement/baseline_psnr*100:+.2f}%)")
        print(f"SSIM æå‡: {ssim_improvement:+.4f} ({ssim_improvement/baseline_ssim*100:+.2f}%)")
        
        print("-" * 70)
        print("ğŸ¯ ç»“è®º:")
        if psnr_recovery > 0 and ssim_recovery > 0:
            print("âœ… PnP-FlowæˆåŠŸæ¢å¤äº†é®æŒ¡åŒºåŸŸçš„ä¿¡æ¯")
            print("âœ… è¯æ˜äº†Flow Matchingå…ˆéªŒåœ¨é®æŒ¡æ¢å¤ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§")
            print("âœ… æ¢å¤åçš„å›¾åƒè´¨é‡æ˜¾è‘—ä¼˜äºé®æŒ¡å›¾åƒ")
        else:
            print("âš ï¸  é®æŒ¡æ¢å¤æ•ˆæœæœ‰é™ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç®—æ³•å‚æ•°")
            
        if psnr_improvement > 0 and ssim_improvement > 0:
            print("âœ… PnP-Flowåœ¨é®æŒ¡+è¶…åˆ†è¾¨ç‡ç»„åˆä»»åŠ¡ä¸Šä¼˜äºä¼ ç»Ÿæ–¹æ³•")
        else:
            print("âš ï¸  åœ¨ç»„åˆä»»åŠ¡ä¸Šç›¸å¯¹ä¼ ç»Ÿæ–¹æ³•çš„ä¼˜åŠ¿æœ‰é™")
            
        print(f"\nğŸ“ å¯¹æ¯”å›¾åƒå·²ä¿å­˜åˆ° ./test_results_occlusion/ ç›®å½•")
        print("   å¯ä»¥ç›´è§‚æ¯”è¾ƒäº”ç§å›¾åƒçš„è§†è§‰æ•ˆæœï¼š")
        print("   1. åŸå§‹é«˜åˆ†è¾¨ç‡å›¾åƒ")
        print("   2. é®æŒ¡åçš„å›¾åƒ")
        print("   3. é™é‡‡æ ·çš„ä½åˆ†è¾¨ç‡å›¾åƒ")
        print("   4. åŒä¸‰æ¬¡æ’å€¼æ¢å¤")
        print("   5. PnP-Flowæ¢å¤")
        print("="*70)
        
    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
